namespace :scraper do
  desc "Test speed improvements and Milkyway fix"
  task speed_test: :environment do
    scraper = UnifiedVenueScraper.new
    scraper.quick_speed_test
  end

  desc "ğŸš€ ULTRA-FAST test with all optimizations (parallel + HTTP-first + caching)"
  task ultra_fast_test: :environment do
    scraper = UnifiedVenueScraper.new(verbose: true, max_parallel: 3)
    scraper.ultra_speed_test
  end

  desc "ğŸŒ ULTRA-FAST N+1 scaling test with candidate venues"
  task :ultra_n_plus_one, [:candidate_limit] => :environment do |t, args|
    candidate_limit = (args[:candidate_limit] || 5).to_i

    puts "ğŸš€ Starting Ultra-Fast N+1 Scaling Test!"
    puts "ğŸ“Š Will test #{UnifiedVenueScraper::PROVEN_VENUES.count} proven + #{candidate_limit} candidate venues"

    scraper = UnifiedVenueScraper.new(verbose: true, max_parallel: 3)
    result = scraper.ultra_fast_n_plus_one_test(candidate_limit)

    puts "\nğŸ‰ N+1 SCALING COMPLETE!"
    puts "âœ… Total success: #{result[:total_successful]} venues"
    puts "ğŸ“Š New gigs discovered: #{result[:total_gigs]}"
    puts "âš¡ Completed in: #{result[:duration]} seconds"

    if result[:candidate_successful] > 0
      puts "\nğŸ† SUCCESS! Found #{result[:candidate_successful]} new working venues!"
      puts "ğŸš€ Ready to scale to hundreds of venues!"
    end
  end

  desc "ğŸ”§ IMPROVED N+1 test with enhanced filtering and error analysis"
  task :improved_n_plus_one, [:candidate_limit] => :environment do |t, args|
    candidate_limit = (args[:candidate_limit] || 10).to_i

    puts "ğŸ”§ IMPROVED N+1 SCALING TEST WITH ENHANCEMENTS!"
    puts "="*60
    puts "ğŸ¯ Testing #{UnifiedVenueScraper::PROVEN_VENUES.count} proven + #{candidate_limit} pre-filtered candidates"
    puts "="*60

    scraper = UnifiedVenueScraper.new(verbose: true, max_parallel: 3)

    # Pre-filter candidates for better success rate
    puts "\nğŸ“‹ Pre-filtering candidate venues..."
    all_candidates = scraper.get_candidate_venues(candidate_limit * 2) # Get more to filter from

    accessible_candidates = []
    all_candidates.each do |venue|
      if scraper.website_accessible?(venue.website)
        accessible_candidates << venue
        puts "  âœ… #{venue.name} - #{venue.website} (accessible)"
        break if accessible_candidates.count >= candidate_limit
      else
        puts "  âŒ #{venue.name} - #{venue.website} (not accessible)"
      end
    end

    puts "\nğŸ“Š Pre-filtering results:"
    puts "  ğŸ¯ Accessible candidates: #{accessible_candidates.count}/#{candidate_limit} target"
    puts "  âš ï¸ Filtered out: #{all_candidates.count - accessible_candidates.count} inaccessible venues"

    # Use the improved test method with accessible venues
    result = scraper.ultra_fast_n_plus_one_test(accessible_candidates.count)

    # Enhanced analysis
    puts "\n" + "="*60
    puts "ğŸ”§ IMPROVED N+1 TEST ANALYSIS:"
    puts "="*60
    puts "âš¡ Total time: #{result[:duration]} seconds"
    puts "ğŸ† Success rate improvement via pre-filtering:"
    puts "  ğŸ“Š Proven venues: #{result[:proven_successful]}/#{UnifiedVenueScraper::PROVEN_VENUES.count} (#{((result[:proven_successful].to_f / UnifiedVenueScraper::PROVEN_VENUES.count) * 100).round(1)}%)"
    puts "  ğŸ¯ Candidate venues: #{result[:candidate_successful]}/#{accessible_candidates.count} (#{accessible_candidates.count > 0 ? ((result[:candidate_successful].to_f / accessible_candidates.count) * 100).round(1) : 0}%)"
    puts "ğŸ“Š Total gigs: #{result[:total_gigs]}"
    puts "âš¡ Performance: #{(result[:total_gigs].to_f / result[:duration]).round(2)} gigs/second"

    if result[:failed_venues].any?
      puts "\nğŸ” FAILURE ANALYSIS:"

      failure_reasons = result[:failed_venues].group_by { |f| f[:reason] }
      failure_reasons.each do |reason, venues|
        puts "  â€¢ #{reason}: #{venues.count} venues"
        venues.each { |v| puts "    - #{v[:venue]}" }
      end
    end

    puts "\nğŸ¯ NEXT STEPS RECOMMENDATIONS:"
    if result[:candidate_successful] > 0
      success_rate = (result[:candidate_successful].to_f / accessible_candidates.count * 100).round(1)
      if success_rate > 30
        puts "  âœ… High success rate (#{success_rate}%) - ready for large scale testing!"
        puts "  ğŸš€ Recommend testing with 50-100 venues next"
      elsif success_rate > 10
        puts "  âš¡ Moderate success rate (#{success_rate}%) - some improvements working"
        puts "  ğŸ”§ Consider further selector enhancements"
      else
        puts "  âš ï¸ Low success rate (#{success_rate}%) - need more improvements"
        puts "  ğŸ” Focus on selector and extraction improvements"
      end
    end
  end

  desc "Test parallel processing only"
  task parallel_test: :environment do
    puts "ğŸš€ PARALLEL PROCESSING TEST"
    puts "="*50

    scraper = UnifiedVenueScraper.new(verbose: true, max_parallel: 3)
    result = scraper.test_proven_venues_parallel(verbose: true)

    puts "\nâœ… Parallel test complete!"
    puts "ğŸ“Š Results: #{result[:successful_venues]}/5 venues, #{result[:total_gigs]} gigs in #{result[:duration]}s"
  end

  desc "Test HTTP-first approach on a single venue"
  task :http_first_test, [:venue_name] => :environment do |t, args|
    venue_name = args[:venue_name] || "Antiknock"

    venue_config = UnifiedVenueScraper::PROVEN_VENUES.find { |v| v[:name] == venue_name }

    unless venue_config
      puts "âŒ Venue '#{venue_name}' not found!"
      puts "Available venues: #{UnifiedVenueScraper::PROVEN_VENUES.map { |v| v[:name] }.join(', ')}"
      exit 1
    end

    puts "ğŸŒ Testing HTTP-first approach on: #{venue_name}"
    puts "URL: #{venue_config[:url]}"

    scraper = UnifiedVenueScraper.new(verbose: true)

    start_time = Time.current
    gigs = scraper.scrape_venue_http_first(venue_config)
    duration = (Time.current - start_time).round(2)

    if gigs && gigs.any?
      valid_gigs = scraper.filter_valid_gigs(gigs)
      puts "\nâœ… HTTP-first SUCCESS!"
      puts "âš¡ Duration: #{duration} seconds"
      puts "ğŸ“Š Raw gigs: #{gigs.count}"
      puts "âœ… Valid gigs: #{valid_gigs.count}"
      puts "ğŸš€ Speed: #{(valid_gigs.count.to_f / duration).round(2)} gigs/second"
    else
      puts "\nâš ï¸ HTTP-first failed, would fall back to browser"
    end
  end

  desc "Test website complexity detection on specific URL"
  task :complexity_test, [:url] => :environment do |t, args|
    url = args[:url] || "https://www.shibuyamilkyway.com"

    puts "ğŸ” Testing website complexity detection for: #{url}"

    scraper = UnifiedVenueScraper.new(verbose: true)
    complexity = scraper.detect_website_complexity(url)

    puts "ğŸ“Š Result: #{complexity}"
    puts "ğŸ¯ This means the scraper will use: #{
      case complexity
      when :simple_html
        'Fast HTML-only mode (JavaScript disabled)'
      when :moderate_js
        'Standard mode (JavaScript enabled)'
      when :complex_js
        'Complex mode (Enhanced JavaScript handling)'
      end
    }"
  end

  desc "Compare old vs new scraper speed with all optimizations"
  task speed_comparison: :environment do
    puts "ğŸ ULTIMATE SPEED COMPARISON TEST"
    puts "="*60

    scraper = UnifiedVenueScraper.new(verbose: false, max_parallel: 3)

    # Test old sequential approach
    puts "\nğŸŒ Testing SEQUENTIAL scraper (old approach)..."
    start_time = Time.current
    sequential_result = scraper.test_proven_venues(verbose: false)
    sequential_time = (Time.current - start_time).round(2)

    # Test new parallel approach
    puts "\nğŸš€ Testing PARALLEL scraper (new approach)..."
    start_time = Time.current
    parallel_result = scraper.test_proven_venues_parallel(verbose: false)
    parallel_time = (Time.current - start_time).round(2)

    puts "\n" + "="*60
    puts "ğŸ“Š ULTIMATE COMPARISON RESULTS:"
    puts "="*60
    puts "ğŸŒ Sequential: #{sequential_time}s â†’ #{sequential_result[:total_gigs]} gigs"
    puts "ğŸš€ Parallel:   #{parallel_time}s â†’ #{parallel_result[:total_gigs]} gigs"
    puts "âš¡ Speed improvement: #{(sequential_time / parallel_time).round(1)}x FASTER!"
    puts "ğŸ’¾ Time saved: #{(sequential_time - parallel_time).round(2)} seconds"
    puts "ğŸ† Efficiency: #{(parallel_result[:total_gigs].to_f / parallel_time).round(2)} gigs/second"

    if parallel_time < 60
      scaling_estimate = (100 * parallel_time / 60).round(2)
      puts "\nğŸ¯ SCALING ESTIMATE:"
      puts "ğŸ“ˆ 100 venues would take approximately #{scaling_estimate} minutes!"
      puts "ğŸŒ Ready for massive venue scaling!"
    end
  end

  desc "Clear complexity cache"
  task clear_cache: :environment do
    cache_file = Rails.root.join('tmp', 'venue_complexity_cache.json')
    if File.exist?(cache_file)
      File.delete(cache_file)
      puts "ğŸ—‘ï¸ Complexity cache cleared!"
    else
      puts "â„¹ï¸ No cache file found."
    end
  end

  desc "ğŸ§  SMART 25-venue test with blacklisting and all enhancements"
  task :smart_25_test => :environment do
    puts "ğŸ§  SMART 25-VENUE TEST WITH FULL OPTIMIZATION SUITE!"
    puts "="*70
    puts "ğŸ¯ Testing 5 proven + 20 smart-filtered candidates"
    puts "ğŸš« Using intelligent blacklisting"
    puts "âš¡ All performance optimizations active"
    puts "="*70

    scraper = UnifiedVenueScraper.new(verbose: true, max_parallel: 4) # Increased parallelism

    # Test with 20 candidates for 25 total venues
    result = scraper.ultra_fast_n_plus_one_test(20)

    puts "\n" + "="*70
    puts "ğŸ§  SMART 25-VENUE TEST RESULTS:"
    puts "="*70
    puts "âš¡ Total time: #{result[:duration]} seconds"
    puts "ğŸ† Success rate: #{result[:total_successful]}/25 (#{((result[:total_successful].to_f / 25) * 100).round(1)}%)"
    puts "ğŸ“Š Proven venue success: #{result[:proven_successful]}/5 (#{((result[:proven_successful].to_f / 5) * 100).round(1)}%)"
    puts "ğŸ¯ Candidate discovery rate: #{result[:candidate_successful]}/20 (#{((result[:candidate_successful].to_f / 20) * 100).round(1)}%)"
    puts "ğŸ“Š Total gigs: #{result[:total_gigs]}"
    puts "âš¡ Performance: #{(result[:total_gigs].to_f / result[:duration]).round(2)} gigs/second"
    puts "ğŸš€ Speed: #{(result[:duration] / 25).round(2)} seconds/venue"

    # Scaling projection
    projected_100 = (100 * result[:duration] / 25 / 60).round(1)
    puts "\nğŸŒ SCALING PROJECTION:"
    puts "ğŸ“ˆ 100 venues: ~#{projected_100} minutes"
    puts "ğŸš€ 1000 venues: ~#{(projected_100 * 10 / 60).round(1)} hours"

    # Enhanced failure analysis
    if result[:failed_venues].any?
      puts "\nğŸ” FAILURE PATTERN ANALYSIS:"
      failure_types = result[:failed_venues].group_by { |f| f[:reason].split(':').first }
      failure_types.each do |type, venues|
        puts "  â€¢ #{type}: #{venues.count} venues"
      end

      puts "\nğŸ’¡ OPTIMIZATION SUGGESTIONS:"
      if failure_types['timeout']
        puts "  ğŸš« Consider longer timeouts or blacklisting timeout-prone sites"
      end
      if failure_types['No gigs found']
        puts "  ğŸ” Selector improvements needed for content-rich sites"
      end
      if failure_types['Blacklisted venue']
        puts "  âœ… Blacklisting working - skipping known problematic venues"
      end
    end

    # Success rate analysis
    candidate_rate = result[:candidate_successful].to_f / 20 * 100
    puts "\nğŸ¯ SUCCESS RATE ASSESSMENT:"
    case candidate_rate
    when 0..5
      puts "  ğŸ”´ Very Low (#{candidate_rate.round(1)}%) - Major selector/approach overhaul needed"
    when 5..15
      puts "  ğŸŸ¡ Low (#{candidate_rate.round(1)}%) - Improvements working but more needed"
    when 15..25
      puts "  ğŸŸ¢ Moderate (#{candidate_rate.round(1)}%) - Good progress, ready for larger tests"
    when 25..40
      puts "  ğŸ’š Good (#{candidate_rate.round(1)}%) - Ready for production scaling"
    else
      puts "  ğŸ† Excellent (#{candidate_rate.round(1)}%) - Exceptional discovery rate!"
    end

    puts "\nğŸ‰ 25-VENUE SMART TEST COMPLETE!"
  end

  desc "ğŸ”ï¸ CONSERVATIVE 50-venue test with safe threading"
  task :safe_50_test => :environment do
    puts "ğŸ”ï¸ CONSERVATIVE 50-VENUE SCALING TEST!"
    puts "="*70
    puts "ğŸ¯ Testing 5 proven + 45 candidates with SAFE threading"
    puts "ğŸ›¡ï¸ Conservative parallel limits to prevent thread exhaustion"
    puts "âš¡ Optimized for reliability over speed"
    puts "="*70

    # Use conservative settings for large scale
    scraper = UnifiedVenueScraper.new(verbose: true, max_parallel: 2) # Conservative threading

    puts "\nğŸ§µ Using 2 parallel threads (conservative for 50 venues)"
    puts "â±ï¸ Estimated completion time: ~15-20 minutes"
    puts "ğŸ’¾ All blacklisting and caching optimizations active"

    start_time = Time.current
    result = scraper.ultra_fast_n_plus_one_test(45)
    end_time = Time.current

    puts "\n" + "="*70
    puts "ğŸ”ï¸ CONSERVATIVE 50-VENUE TEST RESULTS:"
    puts "="*70
    puts "âš¡ Total time: #{result[:duration]} seconds (#{(result[:duration]/60).round(1)} minutes)"
    puts "ğŸ† Success rate: #{result[:total_successful]}/50 (#{((result[:total_successful].to_f / 50) * 100).round(1)}%)"
    puts "ğŸ“Š Proven venue reliability: #{result[:proven_successful]}/5 (#{((result[:proven_successful].to_f / 5) * 100).round(1)}%)"
    puts "ğŸ¯ New venue discovery: #{result[:candidate_successful]}/45 (#{((result[:candidate_successful].to_f / 45) * 100).round(1)}%)"
    puts "ğŸ“Š Total gigs discovered: #{result[:total_gigs]}"
    puts "âš¡ Performance: #{(result[:total_gigs].to_f / result[:duration]).round(2)} gigs/second"
    puts "ğŸš€ Venue processing rate: #{(result[:duration] / 50).round(2)} seconds/venue"

    # Advanced scaling projections
    puts "\nğŸŒ PRODUCTION SCALING PROJECTIONS:"
    puts "ğŸ“ˆ 100 venues: ~#{(100 * result[:duration] / 50 / 60).round(1)} minutes"
    puts "ğŸ­ 500 venues: ~#{(500 * result[:duration] / 50 / 60).round(1)} minutes"
    puts "ğŸš€ 1000 venues: ~#{(1000 * result[:duration] / 50 / 60 / 60).round(1)} hours"

    # Blacklist efficiency analysis
    blacklisted_count = result[:failed_venues].count { |f| f[:reason] == "Blacklisted venue" }
    if blacklisted_count > 0
      puts "\nğŸš« BLACKLIST EFFICIENCY:"
      puts "  âš¡ #{blacklisted_count} venues skipped instantly (no processing waste)"
      puts "  ğŸ’¾ Blacklist preventing: #{blacklisted_count * 10} seconds of timeouts"
      puts "  âœ… Zero crashes due to problematic venues"
    end

    # Success analysis
    if result[:candidate_successful] > 0
      puts "\nï¿½ï¿½ NEW VENUE DISCOVERIES:"
      result[:candidate_successful].times do |i|
        puts "  ğŸ¯ Successfully integrated #{result[:candidate_successful]} new venues into system"
      end
    end

    puts "\nğŸ”ï¸ 50-VENUE CONSERVATIVE TEST COMPLETE!"
    puts "ğŸ¯ System proven stable at 50-venue scale"
    puts "âœ… Ready for production deployment at this scale"
  end
end
